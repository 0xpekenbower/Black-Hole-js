services:

  nginx:
    container_name: nginx
    build:
      context: ./infra/nginx
    ports:
      - 8080:80
    env_file:
      - .env
    profiles: [infra]
    restart: on-failure
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"

  redis:
    container_name: redis
    build:
      context: ./infra/redis
    volumes:
      - redis_data:/data
    profiles: [infra]
    env_file:
      - .env
    restart: on-failure
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"

  postgres_db:
    container_name: postgres_db
    build:
      context: ./infra/postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
    profiles: [infra]
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    command: ["postgres", "-c", "config_file=/var/lib/postgresql/postgresql.conf"]
    env_file:
      - .env
    restart: on-failure
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"
  
  pgadmin:
    container_name: pgadmin
    build:
      context: ./infra/pgadmin
    env_file:
      - .env
    profiles: [pgadmin]
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"
    networks:
      - blackholejs

  kafka:
    container_name: kafka
    build:
      context: ./infra/kafka
    env_file:
      - .env
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 1
    profiles: [infra]
    restart: on-failure
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"


  gateway:
    container_name: gateway
    build:
      context: ./infra/gateway
    env_file:
      - .env
    restart: on-failure
    profiles: [core]
    volumes:
      - ./infra/gateway:/gateway
      - /gateway/node_modules
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"

  auth:
    container_name: auth
    build:
      context: ./services/auth
    env_file:
      - .env
    profiles: [core]
    restart: on-failure
    depends_on:
      - gateway
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"

  chat:
    container_name: chat
    build:
      context: ./services/chat
    profiles: [core]
    env_file:
      - .env
    depends_on:
      - gateway
    restart: on-failure
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"

  dash:
    container_name: dash
    build:
      context: ./services/dash
    env_file:
      - .env
    profiles: [core]
    restart: on-failure
    depends_on:
      - gateway
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"

  game:
    container_name: game
    build:
      context: ./services/game
    env_file:
      - .env
    profiles: [core]
    restart: on-failure
    depends_on:
      - gateway
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"

  frontend:
    container_name: frontend
    build:
      context: ./frontend
    env_file:
      - .env
    profiles: [core]
    restart: on-failure
    networks:
      - blackholejs
    # volumes:
    #   - ./frontend:/app
    #   - /app/node_modules
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"

  setup:
    container_name: setup
    build:
      context: ./setup
    env_file:
      - .env
    restart: on-failure
    profiles: [obsy]
    depends_on:
      - elasticsearch
    networks:
      - blackholejs
    logging:
      driver: fluentd
      options:
        tag: "{{.Name}}.log"
        
  elasticsearch:
    container_name: elasticsearch
    build:
      context: ./infra/elasticsearch
    env_file:
      - .env
    profiles: [obsy]
    volumes:
      - elasticsearch:/usr/share/elasticsearch/data:Z
    environment:
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    restart: on-failure
    networks:
      - blackholejs

  # filebeat:
  #   container_name: filebeat
  #   build:
  #     context: ./infra/filebeat
  #   user: root
  #   command:
  #     - -e
  #     - --strict.perms=false
  #   volumes:
  #     - type: bind
  #       source: /home/aelmrabe/goinfre/docker/containers
  #       target: /var/lib/docker/containers
  #       read_only: true
  #     - logs:/var/log/filebeat:rw
  #   environment:
  #     FILEBEAT_INTERNAL_PASSWORD: ${FILEBEAT_INTERNAL_PASSWORD:-}
  #   networks:
  #     - blackholejs
  #   restart: unless-stopped
  #   profiles: [obsy]
  #   env_file:
  #     - .env
  #   depends_on:
  #     - elasticsearch
  #     - logstash

  logstash:
    container_name: logstash
    build:
      context: ./infra/logstash
    ports:
      - 5044:5044
    profiles: [obsy]
    environment:
      LOGSTASH_PASSWORD: ${LOGSTASH_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    depends_on:
     - elasticsearch
    restart: unless-stopped
    env_file:
      - .env
    networks:
      - blackholejs

  kibana:
    container_name: kibana
    build:
      context: ./infra/kibana
    ports:
      - 5601:5601
    profiles: [obsy]
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    depends_on:
      - elasticsearch
    restart: unless-stopped
    env_file:
      - .env
    networks:
      - blackholejs
    
  fluentd:
    container_name: fluentd
    build:
      context: ./infra/fluentd
    profiles: [infra]
    restart: on-failure
    command:
      - /fluent-bit/bin/fluent-bit
      - --config=/etc/fluent-bit/fluent-bit.conf
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    networks:
      - blackholejs
    env_file:
      - .env
    volumes:
      - fluentbit_storage:/var/log/flb-storage:rw


  apm-server:
    container_name: apm-server
    build:
      context: ./infra/apm
    profiles: [obsy]
    restart: on-failure
    networks:
      - blackholejs
    env_file:
      - .env

  # vector:
  #   container_name: vector
  #   build:
  #     context: ./infra/vector
  #   volumes:
  #     - logs_data_vector:/var/lib/vector:rw
  #     - logs:/var/log/containers:rw
  #   ports:
  #     - 9000:9000
  #     - 8686:8686
  #   profiles: [obsy]
  #   depends_on:
  #     - logstash
  #   restart: on-failure
  #   networks:
  #     - blackholejs

  prometheus:
    container_name: prometheus
    build:
      context: ./infra/prometheus
    restart: on-failure
    profiles: [monitoring]
    volumes:
      - prometheus_data:/prometheus
    depends_on:
      - redis_exporter
      - postgres_exporter
      - kafka_exporter
      - nginx_exporter
      - node_exporter
      - cadvisor
    networks:
      - blackholejs

  grafana:
    container_name: grafana
    build:
      context: ./infra/grafana
    restart: on-failure
    profiles: [monitoring]
    env_file:
      - .env
    networks:
      - blackholejs

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.52.1
    container_name: cadvisor
    restart: on-failure
    profiles: [monitoring]
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - blackholejs

  node_exporter:
    image: prom/node-exporter:v1.9.1
    container_name: node_exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
      - /run/systemd:/run/systemd:ro
    profiles: [monitoring]
    command:
      - --path.procfs=/host/proc
      - --path.rootfs=/rootfs
      - --path.sysfs=/host/sys
      - --collector.processes
      - --collector.systemd
      - --collector.filesystem
    restart: unless-stopped
    networks:
      - blackholejs
    pid: host
    privileged: true

  redis_exporter:
    container_name: redis_exporter
    image: bitnami/redis-exporter:1.73.0
    environment:
      REDIS_ADDR: "redis://redis:6379"
    env_file:
      - .env
    profiles: [monitoring]
    restart: on-failure
    networks:
      - blackholejs

  postgres_exporter:
    container_name: postgres_exporter
    image: bitnami/postgres-exporter:0.17.0
    environment:
      DATA_SOURCE_NAME: "${DATA_SOURCE_NAME}"
    env_file:
      - .env
    profiles: [monitoring]
    restart: on-failure
    networks:
      - blackholejs

  kafka_exporter:
    container_name: kafka_exporter
    image: danielqsj/kafka-exporter 
    command: ["--kafka.server=kafka:9092"]
    profiles: [monitoring]
    environment:
      - KAFKA_BROKERS=kafka:9092
    restart: on-failure
    networks:
      - blackholejs

  nginx_exporter:
    container_name: nginx_exporter
    image: nginx/nginx-prometheus-exporter:1.4
    profiles: [monitoring]
    networks:
      - blackholejs
    restart: on-failure
    command:
      - --nginx.scrape-uri=http://nginx:80/stub_status

volumes:
  redis_data:
  postgres_data:
  elasticsearch:
  prometheus_data:
  fluentbit_storage:

networks:
  blackholejs:
    name: blackholejs
    driver: bridge